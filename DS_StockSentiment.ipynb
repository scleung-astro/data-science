{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Stock Tweet \n",
    "\n",
    "This Jupyter Notebook works on cleaning and processing the comments on various stocks. Given that there are a huge amount of news related to different stock every day, it becomes much more convenient if we can somehow filter all the news to understand their basic sentiment. Even though the sentiment can be unrelated to how the stock price moves, it can act as a reference to the current background of the market. \n",
    "\n",
    "Data taken from Kaggle at \n",
    "https://www.kaggle.com/yash612/stockmarket-sentiment-dataset\n",
    "\n",
    "Prepared by Shing Chi Leung at 27 May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>Industry body CII said #discoms are likely to ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>#Sharemarket LIVE: Sensex off day’s high, up 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1     user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2     user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                     MNTA Over 12.00            1\n",
       "4                                      OI  Over 21.37            1\n",
       "...                                                 ...        ...\n",
       "5786  Industry body CII said #discoms are likely to ...         -1\n",
       "5787  #Gold prices slip below Rs 46,000 as #investor...         -1\n",
       "5788  Workers at Bajaj Auto have agreed to a 10% wag...          1\n",
       "5789  #Sharemarket LIVE: Sensex off day’s high, up 6...          1\n",
       "5790  #Sensex, #Nifty climb off day's highs, still u...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"stock_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a few types of text here. The simplest one is that a certain stock being over or below a certain price, that can be seen as some breakthrough of support or resistance price. The second type is about the news related to a certain company, mostly related to their company decision or big transaction. Finally, there are users comments on a certain stock. In all cases, there is one stock code or more marked by full captial letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3685\n",
       "-1    2106\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The person who prepare the news cut has provided us a nice division of good and bad tweets about stock. They do not differ very much by the number. It will help the machine learning part to have a comprehensive exposure of the possible text related. \n",
    "\n",
    "Before the machine learning part, I will need to remove all symbols and frequent words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kickers on my watchlist  trade method  or meth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user  return for the indicator just  trades fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user id be afraid to short  they are looking l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>industry body said discoms are likely to suffe...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>gold prices slip below rs  as investors book p...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>workers at bajaj auto have agreed to a  wage c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>sharemarket sensex off day’s high up  points n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>sensex nifty climb off days highs still up  ke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     kickers on my watchlist  trade method  or meth...          1\n",
       "1     user  return for the indicator just  trades fo...          1\n",
       "2     user id be afraid to short  they are looking l...          1\n",
       "3                                                  over          1\n",
       "4                                                  over          1\n",
       "...                                                 ...        ...\n",
       "5786  industry body said discoms are likely to suffe...         -1\n",
       "5787  gold prices slip below rs  as investors book p...         -1\n",
       "5788  workers at bajaj auto have agreed to a  wage c...          1\n",
       "5789  sharemarket sensex off day’s high up  points n...          1\n",
       "5790  sensex nifty climb off days highs still up  ke...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all punctuations\n",
    "df[\"Text\"] = df[\"Text\"].str.replace(r\"[-,.\\(\\):;\\'\\\"!\\?#%/]\",\"\")\n",
    "\n",
    "# remove all stock codes\n",
    "df[\"Text\"] = df[\"Text\"].str.replace(r\"[A-Z]+ \", \"\")\n",
    "\n",
    "# turn all characters to lower characters\n",
    "df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "\n",
    "# remove all numbers\n",
    "df[\"Text\"] = df[\"Text\"].str.replace(r\"[0-9]\",\"\")\n",
    "\n",
    "# remove all space\n",
    "df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the processed text remains only the key words, which should be sufficient for the machine learning part to pick up the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kickers on my watchlist  trade method  or method  see prev posts',\n",
       "       'user  return for the indicator just  trades for the year',\n",
       "       'user id be afraid to short  they are looking like a nearmonopoly in ebooks and infrastructureasaservice',\n",
       "       'over', 'over', 'over',\n",
       "       'user if so then the current downtrend will break otherwise just a shortterm correction in medterm downtrend',\n",
       "       'mondays relative weakness',\n",
       "       'ower trend line channel test & volume support',\n",
       "       'will watch tomorrow for entry'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df[\"Text\"].to_numpy()\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"Sentiment\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning of Tweet Sentiment by Classification\n",
    "\n",
    "Now we move on to the second part of the project. We will use machine learning to classify the tweets one by one. In particular, we will do the following steps:\n",
    "\n",
    "1. Use tokens to represent all the words\n",
    "2. Find out the words' relative importance by the Tfidf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('tf', TfidfTransformer())])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"cv\", CountVectorizer()), (\"tf\", TfidfTransformer())])\n",
    "pipeline.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8542"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipeline[\"cv\"].vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vec = pipeline.transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the variable tf_vec storing all the scores each tweet has. We may now decompose the very high dimensional array (8542) into a lower one by SVD decomposition. This will lower the size necessary for storing all the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=50)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd = TruncatedSVD(n_components=50)\n",
    "tsvd.fit(tf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 50)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vec50 = tsvd.transform(tf_vec)\n",
    "tf_vec50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD method is very helpful in minimized the very sparse matrix into a compact one to reduce the storage size. \n",
    "\n",
    "Now we will move on to the machine learning part. In particular, we will use the Random Forest Classifier to classify the tweet. For demonstration and accuracy purpose, I will use the original vector representation of the tweet, rather than the decomposed one. Because the size of the variables is small enough to be done within minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(tf_vec, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.77      0.64       301\n",
      "           1       0.91      0.78      0.84       858\n",
      "\n",
      "    accuracy                           0.77      1159\n",
      "   macro avg       0.73      0.77      0.74      1159\n",
      "weighted avg       0.81      0.77      0.79      1159\n",
      "\n",
      "0.7748058671268335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_pred, test_y))\n",
    "print(accuracy_score(y_pred, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is not particularly high or low. THe precision for positive is quite high, but the negative one is not very enchanting. Partly because sometimes the negative sentiment is hidden by the ironic or sacastic tone, which cannot be captured without a large amount of sample. The accuracy score is about 0.8, which is also acceptable in view of the simple classification we have done. \n",
    "\n",
    "## Applications to Fiducial Tweet\n",
    "\n",
    "Now we will try to test the classifier with some artificial tweet made by me. I randomly make some very similar tweets and we want to see if the classifier can handle the basic task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = [\"this is a good stock\", \n",
    "                  \"this is a bad stock\", \n",
    "                  \"this stock will go up\", \n",
    "                  \"this stock will go down\",\n",
    "                  \"hope for this stock\",\n",
    "                  \"no hope for this stock\"]\n",
    "test_vec = pipeline.transform(test_sentences)\n",
    "rfc.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad = 531\n",
      "no = 5318\n"
     ]
    }
   ],
   "source": [
    "print(\"bad = {}\".format(pipeline[\"cv\"].vocabulary_[\"bad\"]))\n",
    "print(\"no = {}\".format(pipeline[\"cv\"].vocabulary_[\"no\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously we see that there are six sentences with 3 being positive and 3 being negative. However, the classifier can only identify one negative tweet. The major feature of the bad tweet is the use of negative tags like \"bad\" or \"no\". It seems that the classifier does not understand the negativity of these tags. To pick out the reason, we need to examine the tweets with similar features. \n",
    "\n",
    "Let's take a look at the tweet which contains the word bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>option traders bet on bad earnings selling  ja...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>demand for breast implants at alltime highs  g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>wooooow really bad wont touch the applestock w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>if manufacturing index eslts are bad = below</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>feel bad for those stoplosses that got taken out</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>m my position hurt so bad today butt it just s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "289   option traders bet on bad earnings selling  ja...         -1\n",
       "638   demand for breast implants at alltime highs  g...          1\n",
       "1186  wooooow really bad wont touch the applestock w...         -1\n",
       "1738       if manufacturing index eslts are bad = below         -1\n",
       "1842   feel bad for those stoplosses that got taken out          1\n",
       "3794  m my position hurt so bad today butt it just s...          1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Text\"].str.contains(\"bad\")].groupby(\"Sentiment\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user id be afraid to short  they are looking l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it really worries me how everyone expects the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user maykiljil posted that  agree that is goin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>red not ready for break out</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>wow not good for user  sales for the nook were...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>the new wightwatchers ads are more fun and lig...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Sentiment\n",
       "2    user id be afraid to short  they are looking l...          1\n",
       "11   it really worries me how everyone expects the ...          1\n",
       "13   user maykiljil posted that  agree that is goin...          1\n",
       "26                         red not ready for break out         -1\n",
       "107  wow not good for user  sales for the nook were...         -1\n",
       "109  the new wightwatchers ads are more fun and lig...         -1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Text\"].str.contains(\"no\")].groupby(\"Sentiment\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the sampling it shows that the tweets contains a mixed used of terms like \"not\" or \"bad\". Even though they do have negative meaning in the tweet, the overall statement is positive. It seems that the classifier needs to work hard in digesting the overall structure of the sentences in order to improve its accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
